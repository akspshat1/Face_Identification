{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LDA:\n",
        "    def fit(self, X, y):\n",
        "        class_labels = np.unique(y)\n",
        "        class_means = []\n",
        "        overall_mean = np.mean(X, axis=0)\n",
        "\n",
        "        for label in class_labels:\n",
        "            class_X = X[y == label]\n",
        "            class_means.append(np.mean(class_X, axis=0))\n",
        "\n",
        "        self.class_means = np.array(class_means)\n",
        "        self.overall_mean = overall_mean\n",
        "\n",
        "        #between-class scatter matrix\n",
        "        between_class_scatter = np.zeros((X.shape[1], X.shape[1]))\n",
        "        for label, class_mean in zip(class_labels, class_means):\n",
        "            n_samples = X[y == label].shape[0]\n",
        "            diff = (class_mean - overall_mean).reshape(-1, 1)\n",
        "            between_class_scatter += n_samples * np.dot(diff, diff.T)\n",
        "\n",
        "        #within-class scatter matrix\n",
        "        within_class_scatter = np.zeros((X.shape[1], X.shape[1]))\n",
        "        for label, class_mean in zip(class_labels, class_means):\n",
        "            class_X = X[y == label]\n",
        "            diff = class_X - class_mean\n",
        "            within_class_scatter += np.dot(diff.T, diff)\n",
        "\n",
        "        eigen_values, eigen_vectors = np.linalg.eig(np.linalg.inv(within_class_scatter) @ between_class_scatter)\n",
        "\n",
        "        sorted_indices = np.argsort(eigen_values)[::-1]\n",
        "        self.eigen_vectors = eigen_vectors[:, sorted_indices]\n",
        "\n",
        "    def transform(self, X, n_components):\n",
        "        return np.dot(X, self.eigen_vectors[:, :n_components])"
      ],
      "metadata": {
        "id": "B6FzOivJc8YF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train_2d = X_train_filtered.reshape(X_train_filtered.shape[0], -1)\n",
        "X_test_2d = X_test_filtered.reshape(X_test_filtered.shape[0], -1)\n",
        "\n",
        "lda = LDA(n_components=None)\n",
        "X_train_lda = lda.fit_transform(X_train_2d, y_train_filtered)\n",
        "X_test_lda = lda.transform(X_test_2d)\n",
        "\n",
        "classifiers = {\n",
        "    'SVM': SVC(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "for clf_name, clf in classifiers.items():\n",
        "    clf.fit(X_train_lda, y_train_filtered)\n",
        "    y_pred = clf.predict(X_test_lda)\n",
        "    accuracy = accuracy_score(y_test_filtered, y_pred)\n",
        "    print(f\"{clf_name} accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGAjRA9xc-Kg",
        "outputId": "f6e28dde-de40-436c-ccfe-f2784048689d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM accuracy: 0.8837209302325582\n",
            "Random Forest accuracy: 0.875968992248062\n",
            "KNN accuracy: 0.8643410852713178\n",
            "Gradient Boosting accuracy: 0.8372093023255814\n"
          ]
        }
      ]
    }
  ]
}